---
title: Three lessons every online marketer can learn from Moneyball
date: 2013-09-03 00:00:00 -04:00
categories:
- Marketing
- What I’m Reading
tags:
- A/B testing
- Baseball
- Books
- Cognitive bias
- Consumer behavior
- Flint McGlaughlin
- MECLABS
- Obama
- Optimization
- Social proof
- Testing
author: Nathaniel Ward
layout: post
---

At first blush, *[Moneyball][1]* has nothing at all to do with marketing. After all, it’s a book about baseball. But there are three important lessons online marketers can draw from the book.

## 1. Start with a clear objective, and focus all your activity on that

To ensure the Oakland As won more games than anyone else on a shoestring budget, general manager Billy Beane identified those metrics, like on-base percentage, most correlated with scoring runs and winning games. He then ensured his lineup included players that could get on base, and  discouraged tactics like bunting and stealing that kept players from getting on base.

Online marketers should use a similar goal-oriented approach. Start with your highest measurable objective (sales or brand awareness, for example), and then identify those activities (sending e-mails or running a particular kind of ad) and customer behaviors (like commenting or browsing a product page) most correlated with achieving that objective.

And since you no doubt have limited resources, you should focus on these activities that give you the most bang for your buck—and stop doing those things with low or even negative correlation with success.

## 2. Experimental data beats gut instinct every time

Experience and gut instinct taught baseball scouts to value traits in their recruits like speed and even visual appearance. Their judgment often failed dramatically, yet they were unwilling to change how they did things. Based gut instinct and subjective judgement, Billy Beane himself was drafted out of high school as a top prospect, but he washed out after just a few years—a costly failure.

As Oakland’s manager, Beane took a different approach. He relied on data, not instinct, in player recruitment, and favored traits like on-base percentage that data showed contributed to winning. This open-minded approach paid dividends.

Marketers must be similarly humble and open-minded. You cannot assume that what you think *must* be right is necessarily right. For one thing, you are not your target audience, so your preferences about how you’d like to be marketed to are irrelevant. For another, you share the same failing as every other human being: you’re terrible at spotting patterns, and [you tend to see patterns that aren’t there][2]. 

Not to put too fine a point on it, but your gut instinct as a marketer is probably wrong. Even the wildly successful marketers on the 2012 Obama campaign [were often very wrong when asked to predict winners and losers][3]. They succeeded because they relied on hard data.

## 3. Expertise and experience are not the same as knowing what you’re talking about

Baseball is riddled with experts and analysts who make decisions based on “best practices” and “experience.” These insiders ridicule those who do differently. Billy Beane succeeded because he questioned the assumptions of the incumbents, which allowed him to identify what actually worked.

Online marketing is no different. Any number of charlatans will preach to you about the next big thing—text-to-donate will be huge any day now! Perhaps more detrimental are the white papers about best practices and industry benchmarks that are too often used as how-to guides. This is simply [social proof][4] in action: you do something because you believe others must be correct.

But why do you really care what everyone else is doing? What evidence do you have that someone else has identified the best way of doing things? Remember <span class="caps">MECLABS</span> president Flint McLaughlin’s warning: “best practices on the internet are typically pooled ignorance.”

Even if someone else has perfected things for their audience, they have a different set of customers, so you shouldn’t blindly copy what they do for yours. Instead, use others’ work as a starting point for testing, not as an end point. Use A/​B testing to find out if their approach works better than yours—and find out *why* it works or doesn’t work.

**What lessons would you draw from Moneyball?**

 [1]: http://www.amazon.com/exec/obidos/ASIN/0393057658/nathward-20
 [2]: http://en.wikipedia.org/wiki/Confirmation_bias
 [3]: http://www.nathanielward.net/2012/12/your-gut-instincts-as-a-marketer-are-probably-wrong/
 [4]: http://en.wikipedia.org/wiki/Social_proof